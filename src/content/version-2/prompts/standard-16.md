---
caption: Standard 16
title: Identify performance indicators
description: Identify performance indicators for the service, including the 4 mandatory key performance indicators (KPIs) defined in the manual. Establish a benchmark for each metric and make a plan to enable improvements.
tags:
  - prompt
  - version-2
layout: prompt
permalink: /version-2/standard-16/prompts/
eleventyNavigation:
  key: version-2-standard-16-prompts
  title: Standard 16 prompts
  parent: version-2
---

## Alpha

### Questions

- Have you identified the behaviour, characteristics and dependencies of the new service and the factors that influence the choice of metrics and data sources for those metrics?
- How are you measuring the performance of the existing service (if applicable) across digital, non-digital and assisted digital channels?
- Have you identified which new or existing (if applicable) measures will form the basis of the new service baseline?
- Have you identified (in addition to the 4 mandatory KPI’s) other measures for the new service and where the data will be provided from?
- Have you investigated how the service is expected to perform in comparison with similar services?

### Evidence

Service Manager able to:

- demonstrate how they currently measure the performance of the existing service (if applicable) and which measures will provide a baseline for the new service and why they have been chosen.
- explain measures for the new service, including dependent transactions (e.g. authentication, search etc), and why they have been chosen.
- identify where the data for the metrics will come from.
- explain their plan and scope for measuring cost per transaction (or equivalent†).
- explain how user satisfaction data will captured, and the choice of benchmark.
- explain how completion rate (or equivalent*) data will be captured, and the choice of benchmark, including the selection of start and end point and eligibility and transaction stages.
- explain how usage volumes for the existing (if applicable) and new services (across channels) are or will be measured and how usage trends and insights drawn from similar services are informing their digital take-up plans.
- explain their plan or benchmark for each additional metric identified for the new service.
- demonstrate they have registered the service with the performance platform and validated that the platform can support the metrics the service dashboard should present.

† non-transactional user journeys

## Beta

### Questions

- Have you identified the behaviour, characteristics and dependencies of the new service and the factors that influence the choice of metrics and data sources for those metrics?
- Have these metrics changed since alpha review, and if so why?
- How are you measuring the performance of the existing (if applicable) and beta service across digital, non-digital and assisted-digital channels?
- How are you capturing user journey data for the new service during beta?
- How are you collecting cost per transaction (or equivalent†) data during beta?
- How are you collecting usage volume or digital take up data during beta?
- How are you collecting cost per transaction (or equivalent*) data during beta?
- How are you collecting other identified metrics data during beta?
- How are data analytics and user research being used to identify percentage of users who could channel shift and who will need assisted digital services?
- What are their plans for engaging with service users, delivery partners or other stakeholders during the beta phase?

### Evidence

Service Manager able to:

- explain changes to the metrics collected since alpha and the reasons for change (if any).
- show how they currently measure the performance of the existing service (if applicable) and which measures will provide a baseline for the new service.
- show how they are collecting users journey data for the new service during beta (using a chosen analytics package).
- show how they are collecting and calculating cost per transaction (or equivalent†) during beta.
- show how they are collecting user satisfaction data during beta (GOV.UK ‘done page’ questionnaire or other).
- show how they are collecting completion rate (or equivalent†) data during beta.
- show how they are collecting other metrics data (including journey stage information) during beta.
- explain how they plan to increase digital take up during beta.
- explain how they are assessing potential for channel shift and level of assisted digital services required.
- explain how they are engaging with beta users, delivery partners and other stakeholders to manage transition to live service.
- explain how they will track migration from online to offline.

† non-transactional user journeys

## Live

### Questions

- Have you changed the behaviour, characteristics and dependencies of the new service and the factors that influence the choice of metrics and data sources for those metrics?
- Have these metrics changed since beta assessment and if so why?
- How are you measuring the performance of the existing (if applicable) and new service across digital, non-digital and assisted-digital channels?

### Evidence

Using the Performance Platform dashboard, the Service Manager is able to:

- explain and show how they are reporting user satisfaction on their dashboard.
- explain how they are planning to increase user satisfaction after the service goes live.
- explain who will monitor user satisfaction after the service is live.
- explain and show how they are reporting completion rates (or equivalent†) on their dashboard.
- explain how they are planning to increase completion rates after the service goes live.
- explain who will monitor completion rates after the service is live.
- explain and show how they are reporting cost per transaction (or equivalent*) on their dashboard.
- explain how they are planning to achieve a low cost per transaction after the service goes live.
- explain who will monitor cost per transaction after the service is live.
- explain and show how they are reporting digital take up on their dashboard, and - explain how it measures channel shift.
- explain how they are planning to increase digital uptake after the service goes live.
- explain realistic planning to increase digital uptake (thereby reducing reliance on assisted digital) after the service goes live.
- explain who will monitor digital take up after the service is live.
- explain and show other additional metrics supporting the service on their dashboard.
- explain how they are planning to use these metrics to improve the service.
- explain who will monitor these metrics.
- demonstrate that delivery partners and other stakeholders are actively promoting/supporting digital delivery.
- identify future metrics and how they will be used to improve the service.
- outline a timescale when these metrics will be available.

† non-transactional user journeys
